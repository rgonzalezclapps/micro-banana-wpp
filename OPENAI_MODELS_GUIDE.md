# ğŸ¤– OpenAI Models Guide - Reasoning vs Non-Reasoning

**Version**: PCTMv1.6.0-11  
**Date**: November 14, 2025  
**Purpose**: Technical reference for OpenAI model selection and configuration  

---

## ğŸ¯ Model Comparison

### **GPT-5 (Original)** - Reasoning Always ON

**Configuration**:
```javascript
{
  model: "gpt-5",
  max_output_tokens: 4096,        // NOT max_completion_tokens
  reasoning_effort: "high",       // Default, cannot change
  verbosity: "medium",            // Optional
  // temperature NOT supported
  // top_p NOT supported
  streaming: false
}
```

**Characteristics**:
- âœ… Highest quality reasoning and planning
- âœ… Best for complex tasks requiring step-by-step thinking
- âŒ SLOW: 20-30s due to reasoning tokens (800-1000 tokens)
- âŒ Cannot disable reasoning
- âŒ Traditional parameters (temperature, top_p) NOT supported
- ğŸ’° Most expensive

**Use Cases**:
- Complex problem solving
- Multi-step planning
- Code generation with architecture decisions
- NOT recommended for simple tasks or chatbots

---

### **GPT-5.1** - Reasoning Optional

**Configuration**:
```javascript
{
  model: "gpt-5.1",
  max_output_tokens: 4096,
  reasoning_effort: "none",       // â­ Can disable reasoning!
  verbosity: "low",
  streaming: false
}
```

**Reasoning Effort Options**:
- `none`: No reasoning (fast, ~5-10s)
- `minimal`: Light reasoning (~10-15s)
- `low`: Some reasoning (~15-20s)
- `medium`: Moderate reasoning (~20-25s)
- `high`: Full reasoning (~25-30s)

**Characteristics**:
- âœ… Flexible: Can disable reasoning for speed
- âœ… Fast when reasoning_effort='none' (5-10s)
- âœ… GPT-5 quality when reasoning enabled
- âŒ Still doesn't support temperature/top_p
- ğŸ’° Expensive (same as GPT-5)

**Use Cases**:
- Tasks that sometimes need reasoning, sometimes don't
- Quality priority with speed flexibility
- May not be widely available yet

---

### **GPT-5-mini** - No Reasoning (RECOMMENDED)

**Configuration**:
```javascript
{
  model: "gpt-5-mini",
  max_completion_tokens: 4096,    // Standard parameter
  temperature: 1,                 // âœ… Supported
  top_p: 1,                       // âœ… Supported
  streaming: false
}
```

**Characteristics**:
- âœ… FAST: 3-8s response time
- âœ… No reasoning tokens (direct response)
- âœ… Supports ALL traditional parameters
- âœ… Excellent quality for most tasks
- âœ… 70% cheaper than GPT-5
- âŒ No advanced reasoning capability

**Use Cases**:
- Chatbots and conversational AI âœ…
- Image description and analysis âœ…
- Creative writing and content generation âœ…
- Simple Q&A âœ…
- **PERFECT for Foto Producto AI** âœ…

---

## ğŸ“Š Performance Comparison (Real Data)

### **Test: Simple "Hola" Message**

| Model | OpenAI Time | Total Time | Reasoning Tokens | Cost |
|-------|-------------|------------|------------------|------|
| **gpt-5** | 30-31s | 35-36s | 800-1000 | $0.05 |
| **gpt-5-mini** (expected) | 3-8s | 7-13s | 0 | $0.015 |
| **Improvement** | **4-10x faster** | **2.7-5x faster** | **100% eliminated** | **70% cheaper** |

---

## ğŸ› ï¸ How to Switch Models

### **Using updateAgentModel.js Tool**:

```bash
# Switch to gpt-5-mini (RECOMMENDED)
node tools/updateAgentModel.js 50151 gpt-5-mini false 4096

# Switch to gpt-5 (if you need reasoning)
node tools/updateAgentModel.js 50151 gpt-5 false 4096

# Enable streaming for better UX
node tools/updateAgentModel.js 50151 gpt-5-mini true 4096

# Reduce max tokens for speed
node tools/updateAgentModel.js 50151 gpt-5-mini false 2048

# Always clear cache after
node tools/clearAgentCache.js 69157006d7b5fc82c033dc86
```

### **Direct MongoDB Update**:

```javascript
db.agents.updateOne(
  { instanceId: "50151" },
  { 
    $set: { 
      "modelConfig.model": "gpt-5-mini",
      "metadata.lastModified": new Date()
    }
  }
)
```

---

## âš™ï¸ Parameter Compatibility

### **Reasoning Models (GPT-5, GPT-5.1 with effort)**:
```javascript
âœ… max_output_tokens
âœ… reasoning_effort
âœ… verbosity
âœ… streaming
âŒ temperature (NOT supported)
âŒ top_p (NOT supported)
âŒ logit_bias (NOT supported)
âŒ max_completion_tokens (use max_output_tokens)
```

### **Non-Reasoning Models (GPT-5-mini, GPT-4o)**:
```javascript
âœ… max_completion_tokens
âœ… temperature
âœ… top_p
âœ… frequency_penalty
âœ… presence_penalty
âœ… logit_bias
âœ… streaming
âŒ reasoning_effort (not applicable)
âŒ verbosity (not applicable)
```

---

## ğŸ¯ Current Configuration (After Update)

**Agent**: Maxi Prod (instanceId: 50151)  
**MongoDB ID**: 69157006d7b5fc82c033dc86

```javascript
{
  name: "Maxi Prod",
  modelConfig: {
    model: "gpt-5-mini",          // â­ UPDATED
    maxCompletionTokens: 4096,
    temperature: 1,
    streaming: false
  },
  imageContextConfig: {
    historyMode: "low",
    maxHistoricalImages: 20,
    enableAIObservation: true
  }
}
```

**Expected Performance**:
```
OpenAI processing: 3-8s (vs 30s before)
Total time: 7-13s (vs 36s before)
Overhead (our system): ~4-5s âœ…
```

---

## ğŸ“ˆ Expected Improvements

### **Response Time**:
```
Before: 36 seconds (too slow)
After:  7-13 seconds (acceptable) âœ…
Improvement: 2.7-5x faster âš¡
```

### **Token Cost**:
```
Before: ~10,000 tokens/request
After:  ~3,000 tokens/request (no reasoning tokens)
Savings: 70% cost reduction ğŸ’°
```

### **User Experience**:
```
Before: Timeout anxiety, user waits forever
After:  "Instant" feeling, natural conversation âœ…
```

---

## ğŸ§ª Testing After Model Change

### **Test Scenario**: Send "Hola"

**Expected Logs**:
```
[+0ms] âš¡ FIRST message - processing IMMEDIATELY
[+2,000ms] OpenAI request start
[+5,000ms] OpenAI response received (3s vs 30s before) âœ…
[+7,000ms] Message sent
[+7,200ms] Complete

Total: ~7 seconds âœ… (vs 36s before)
```

**Expected Token Usage**:
```json
{
  "usage": {
    "prompt_tokens": ~8000,
    "completion_tokens": ~300-500 (NO reasoning_tokens âœ…),
    "total_tokens": ~8500,
    "completion_tokens_details": {
      "reasoning_tokens": 0  // â­ ZERO reasoning tokens
    }
  }
}
```

---

## ğŸ“ Key Learnings

### **1. Reasoning Tokens in GPT-5**:
- GPT-5 has "extended thinking" built-in
- Causes 800-1000 reasoning tokens per request
- Adds 20-30s of latency
- CANNOT be disabled in GPT-5 original
- Only GPT-5.1 supports `reasoning_effort: 'none'`

### **2. Model Selection Matters**:
- Use GPT-5 for complex reasoning tasks only
- Use GPT-5-mini for speed and general tasks
- Use GPT-5.1 when you need flexibility

### **3. Parameter Compatibility**:
- Reasoning models have different parameter sets
- Temperature NOT supported in GPT-5/5.1 (with reasoning)
- Always check model compatibility docs

---

## ğŸ“š Official Documentation References

1. **OpenAI GPT-5 Models**: https://platform.openai.com/docs/models/gpt-5
2. **Azure Reasoning Models**: https://learn.microsoft.com/en-us/azure/ai-foundry/openai/how-to/reasoning
3. **GPT-5.1 Guide**: https://platform.openai.com/docs/guides/latest-model
4. **AI SDK Provider Docs**: https://ai-sdk.dev/providers/ai-sdk-providers/openai

---

**Current Model**: `gpt-5-mini` âœ…  
**Status**: Production Ready  
**Expected Performance**: 7-13s total (3-8s OpenAI + 4-5s overhead)

